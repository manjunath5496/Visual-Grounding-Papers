# Visual Grounding Papers

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(1).pdf" style="text-decoration:none;">Video Object Segmentation with
Language Referring Expressions</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(2).pdf" style="text-decoration:none;">Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(3).pdf" style="text-decoration:none;">Real-Time Referring Expression Comprehension by Single-Stage Grounding Network</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(4).pdf" style="text-decoration:none;">Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(5).pdf" style="text-decoration:none;">Grounded Video Description</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(6).pdf" style="text-decoration:none;">VL-BERT: Pre-training of Generic Visual-Linguistic Representations</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(7).pdf" style="text-decoration:none;">Dynamic Graph Attention for Referring Expression Comprehension</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(8).pdf" style="text-decoration:none;"> Referring Expression Object Segmentation with Caption-Aware Consistency </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(9).pdf" style="text-decoration:none;">ALFRED:
A Benchmark for Interpreting Grounded Instructions for Everyday Tasks</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(10).pdf" style="text-decoration:none;">Localizing Moments in Video with Temporal Language</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(11).pdf" style="text-decoration:none;">TIGEr: Text-to-Image Grounding for Image Caption Evaluation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(12).pdf" style="text-decoration:none;">Interpretable Visual Question Answering by Visual Grounding from Attention Supervision Mining</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(13).pdf" style="text-decoration:none;">Actor and Observer: Joint Modeling of First and Third-Person Videos</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(14).pdf" style="text-decoration:none;">Relationship-Embedded Representation
Learning for Grounding Referring Expressions</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(15).pdf" style="text-decoration:none;">Dynamic Multimodal Instance Segmentation Guided by Natural Language Queries</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(16).pdf" style="text-decoration:none;">Referring Relationships</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(17).pdf" style="text-decoration:none;">Learning to Compose and Reason with
Language Tree Structures for Visual Grounding</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(18).pdf" style="text-decoration:none;">Learning Cross-Modal Context Graph for Visual Grounding</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(19).pdf" style="text-decoration:none;">Improving One-stage Visual Grounding by Recursive Sub-query Construction</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(20).pdf" style="text-decoration:none;">Grounded Objects and Interactions for Video Captioning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(21).pdf" style="text-decoration:none;">CLEVR-Ref+: Diagnosing Visual Reasoning with Referring Expressions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(22).pdf" style="text-decoration:none;">Cross-Modal Self-Attention Network for Referring Image Segmentation</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(23).pdf" style="text-decoration:none;">An End-to-End Approach to Natural Language Object Retrieval via Context-Aware Deep Reinforcement Learning</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(24).pdf" style="text-decoration:none;">UNITER: UNiversal Image-TExt
Representation Learning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(25).pdf" style="text-decoration:none;">ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(26).pdf" style="text-decoration:none;">Zero-Shot Grounding of Objects from Natural Language Queries</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(27).pdf" style="text-decoration:none;">Adaptive Reconstruction Network for Weakly Supervised Referring Expression Grounding</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(28).pdf" style="text-decoration:none;">Deep Fragment Embeddings for Bidirectional Image Sentence Mapping</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(29).pdf" style="text-decoration:none;">Modeling Context in Referring Expressions </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(30).pdf" style="text-decoration:none;">Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(31).pdf" style="text-decoration:none;">Refer-it-in-RGBD: A Bottom-up Approach for 3D Visual Grounding in RGBD Images</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(32).pdf" style="text-decoration:none;">Phrase Grounding by Soft-Label Chain Conditional Random Field</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(33).pdf" style="text-decoration:none;">Bi-directional Relationship Inferring Network for Referring Image Segmentation</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(34).pdf" style="text-decoration:none;">Segmentation from Natural Language
Expressions</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(35).pdf" style="text-decoration:none;">Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(36).pdf" style="text-decoration:none;">Differentiable Scene Graphs</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(37).pdf" style="text-decoration:none;">TransVG: End-to-End Visual Grounding with Transformers</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(38).pdf" style="text-decoration:none;">MAF: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(39).pdf" style="text-decoration:none;">Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(40).pdf" style="text-decoration:none;">Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(41).pdf" style="text-decoration:none;">Bundled Object Context for Referring Expressions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(42).pdf" style="text-decoration:none;">Deep Attribute-preserving Metric Learning for Natural Language Object Retrieval</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(43).pdf" style="text-decoration:none;">Multimodal Compact Bilinear Pooling
for Visual Question Answering and Visual Grounding</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(44).pdf" style="text-decoration:none;">Multilevel Language and Vision Integration for Text-to-Clip Retrieval</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(45).pdf" style="text-decoration:none;">A Fast and Accurate One-Stage Approach to Visual Grounding</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(46).pdf" style="text-decoration:none;">Modularized Textual Grounding for Counterfactual Resilience</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(47).pdf" style="text-decoration:none;">Modeling Context Between Objects for
Referring Expression Understanding</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(48).pdf" style="text-decoration:none;">Knowledge Aided Consistency forWeakly Supervised Phrase Grounding</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(49).pdf" style="text-decoration:none;">An Attention-based Regression Model for Grounding Textual Phrases in Images</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(50).pdf" style="text-decoration:none;">Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(51).pdf" style="text-decoration:none;">Phrase LocalizationWithout Paired Training Examples</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(52).pdf" style="text-decoration:none;">ImprovingWeakly Supervised Visual Grounding by Contrastive Knowledge Distillation</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(53).pdf" style="text-decoration:none;">Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(54).pdf" style="text-decoration:none;">Revisiting Image-Language Networks for Open-ended Phrase Detection </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(55).pdf" style="text-decoration:none;">VisualBERT: A Simple and Performant Baseline for Vision and Language</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(56).pdf" style="text-decoration:none;">MSRC: Multimodal Spatial Regression with Semantic Context for Phrase Grounding </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(57).pdf" style="text-decoration:none;">Object Captioning and Retrieval with Natural Language</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(58).pdf" style="text-decoration:none;">Temporal Localization of Moments in Video Collections with Natural Language</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(59).pdf" style="text-decoration:none;">Give Me Something to Eat:
Referring Expression Comprehension with Commonsense Knowledge</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(60).pdf" style="text-decoration:none;">Grounding Referring Expressions in Images by Variational Context </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(61).pdf" style="text-decoration:none;">Weakly-supervised Visual Grounding of Phrases with Linguistic Structures</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(62).pdf" style="text-decoration:none;">Dense-Captioning Events in Videos</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(63).pdf" style="text-decoration:none;">Discriminative Triad Matching
and Reconstruction for Weakly Referring Expression Grounding</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(64).pdf" style="text-decoration:none;">AI2-THOR: An Interactive 3D Environment for Visual AI</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(65).pdf" style="text-decoration:none;">Generation and Comprehension of Unambiguous Object Descriptions </a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(66).pdf" style="text-decoration:none;">A Real-Time Cross-modality Correlation Filtering Method for Referring Expression Comprehension</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(67).pdf" style="text-decoration:none;">Deep Visual-Semantic Alignments for Generating Image Descriptions</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(68).pdf" style="text-decoration:none;">Modeling Relationships in Referential Expressions with Compositional Modular Networks</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(69).pdf" style="text-decoration:none;">Grounding of Textual Phrases in Images by Reconstruction</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(70).pdf" style="text-decoration:none;">Generating Visual Explanations</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(71).pdf" style="text-decoration:none;">Multi-modal Circulant Fusion for Video-to-Language and Backward</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(72).pdf" style="text-decoration:none;">Cops-Ref: A new Dataset and Task on Compositional Referring Expression Comprehension</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(73).pdf" style="text-decoration:none;">Multi-task Collaborative Network for Joint Referring Expression Comprehension and Segmentation</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(74).pdf" style="text-decoration:none;">Natural Language Object Retrieval</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(75).pdf" style="text-decoration:none;">Joint Event Detection and Description in Continuous Video Streams</a></li>                        
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(76).pdf" style="text-decoration:none;">A Joint Speaker-Listener-Reinforcer Model for Referring Expressions</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(77).pdf" style="text-decoration:none;">ReferItGame: Referring to Objects in Photographs of Natural Scenes</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(78).pdf" style="text-decoration:none;">MAC: Mining Activity Concepts for Language-based Temporal Localization</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(79).pdf" style="text-decoration:none;">NeighbourhoodWatch: Referring Expression Comprehension via Language-guided Graph Attention Networks</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(80).pdf" style="text-decoration:none;">TALL: Temporal Activity Localization via Language Query</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(81).pdf" style="text-decoration:none;">Habitat: A Platform for Embodied AI Research</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(82).pdf" style="text-decoration:none;">Referring Image Segmentation via Recurrent Refinement Networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(83).pdf" style="text-decoration:none;">Key-Word-Aware Network for Referring
Expression Image Segmentation</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(84).pdf" style="text-decoration:none;">Visual Grounding with Transformers</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(85).pdf" style="text-decoration:none;">Using Syntax to Ground Referring Expressions in Natural Images</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(86).pdf" style="text-decoration:none;">LXMERT: Learning Cross-Modality Encoder Representations from Transformers</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(87).pdf" style="text-decoration:none;">Semantic Proposal for Activity Localization in Videos via Sentence Query</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(88).pdf" style="text-decoration:none;">MAttNet: Modular Attention Network for Referring Expression Comprehension</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(89).pdf" style="text-decoration:none;">What You See is What You Get:
Visual Pronoun Coreference Resolution in Dialogues</a></li>
  
  
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(90).pdf" style="text-decoration:none;">Rethinking Diversified and Discriminative Proposal Generation for Visual Grounding</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(91).pdf" style="text-decoration:none;">Referring Expression Generation and Comprehension via Attributes</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(92).pdf" style="text-decoration:none;">Graph-Structured Referring Expression Reasoning in The Wild</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(93).pdf" style="text-decoration:none;"> MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(94).pdf" style="text-decoration:none;">Weakly Supervised Video Moment Retrieval From Text Queries</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(95).pdf" style="text-decoration:none;">PIRC Net : Using Proposal Indexing, Relationships and Context for Phrase Grounding</a></li>  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(96).pdf" style="text-decoration:none;">Improving Referring Expression Grounding with Cross-modal Attention-guided Erasing</a></li> 
  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(97).pdf" style="text-decoration:none;">Countering Language Drift via Visual Grounding</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(98).pdf" style="text-decoration:none;">Revisiting Visual Grounding</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(99).pdf" style="text-decoration:none;">Learning to Assemble Neural Module Tree Networks for Visual Grounding</a></li>  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(100).pdf" style="text-decoration:none;">Neural Sequential Phrase Grounding (SeqGROUND)</a></li>  
  
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(101).pdf" style="text-decoration:none;">Conditional Image-Text Embedding Networks</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(102).pdf" style="text-decoration:none;">Grounding Action Descriptions in Videos</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(103).pdf" style="text-decoration:none;">Temporal Modular Networks for Retrieving Complex Compositional Activities in Videos</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(104).pdf" style="text-decoration:none;">Query-guided Regression Network with Context Policy for Phrase Grounding</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(105).pdf" style="text-decoration:none;">Read,Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(106).pdf" style="text-decoration:none;">Phrase Localization and Visual Relationship Detection with Comprehensive Image-Language Cues</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(107).pdf" style="text-decoration:none;">Learning Deep Structure-Preserving Image-Text Embeddings</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(108).pdf" style="text-decoration:none;">Visual Grounding via Accumulated Attention</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(109).pdf" style="text-decoration:none;">Unsupervised Alignment of Actions in Video with Text Descriptions</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(110).pdf" style="text-decoration:none;">Language-driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model </a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(111).pdf" style="text-decoration:none;">To Find Where You Talk: Temporal Sentence Localization in Video with Attention Based Location Regression</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(112).pdf" style="text-decoration:none;">Comprehension-guided referring expressions</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(113).pdf" style="text-decoration:none;">Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(114).pdf" style="text-decoration:none;">Grounding learning of modifier dynamics: An application to color naming</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(115).pdf" style="text-decoration:none;">Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(116).pdf" style="text-decoration:none;">Recurrent Multimodal Interaction for Referring Image Segmentation</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(117).pdf" style="text-decoration:none;">Localizing Moments in Video with Natural Language</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(118).pdf" style="text-decoration:none;">Contrastive Learning for Weakly Supervised Phrase Grounding</a></li>  
   
  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(119).pdf" style="text-decoration:none;">Ref-NMS:
Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(120).pdf" style="text-decoration:none;">Scene-Intuitive Agent for Remote Embodied Visual Grounding</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(121).pdf" style="text-decoration:none;">Relation-aware Instance Refinement forWeakly Supervised Visual Grounding</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(122).pdf" style="text-decoration:none;">MDETR - Modulated Detection for End-to-End Multi-Modal Understanding </a></li>  
     
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(123).pdf" style="text-decoration:none;">Disentangled Motif-aware Graph Learning for Phrase Grounding</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Grounding-Papers/blob/master/v(124).pdf" style="text-decoration:none;">GuessWhat?! Visual object discovery through multi-modal dialogue</a></li>   
   
   </ul>
     
     
     
